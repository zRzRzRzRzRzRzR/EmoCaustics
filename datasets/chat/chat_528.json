[
    {
        "sentence": "几个月前，我去了一个不愿透露名字的国家。之所以不透露名字，是因为我提到了这个国家，结果那里的大使专门来我办公室拜访。",
        "Holder": "2",
        "Target": "国家名称",
        "Aspect": "保密原因",
        "Opinion": "需要保密",
        "Sentiment": "neutral",
        "Rationale": "提到国家名称后大使来访"
    },
    {
        "sentence": "我们有四个人：蒙加尼、皮塔、皮特·韦尔、奥斯卡·范·赫尔登和我。我们到了机场，进入这个国家时，必须把护照放在一台机器上，机器旁边有一台摄像头盯着你。",
        "Holder": "2",
        "Target": "机场安检流程",
        "Aspect": "流程描述",
        "Opinion": "描述流程",
        "Sentiment": "neutral",
        "Rationale": "描述进入国家时的安检流程"
    },
    {
        "sentence": "所以，作为领队，我是第一个去的。我照做了，但机器无法识别我，拒绝了我的通行。",
        "Holder": "2",
        "Target": "机器识别",
        "Aspect": "识别结果",
        "Opinion": "未能识别",
        "Sentiment": "negative",
        "Rationale": "机器无法识别自己"
    },
    {
        "sentence": "接着是皮特·韦尔。他的祖先实际上是英国人。他也做了同样的事情，把护照放到机器上，摄像头看了他一眼，就允许他通过。",
        "Holder": "2",
        "Target": "皮特·韦尔的通行",
        "Aspect": "通行结果",
        "Opinion": "顺利通过",
        "Sentiment": "neutral",
        "Rationale": "皮特·韦尔顺利通过"
    },
    {
        "sentence": "请不要尝试发音，你会把舌头咬到的。然后，机器也没有识别他，拒绝了他的通行。",
        "Holder": "2",
        "Target": "机器识别",
        "Aspect": "识别结果",
        "Opinion": "未能识别",
        "Sentiment": "negative",
        "Rationale": "机器未能识别皮特·韦尔"
    },
    {
        "sentence": "然后是奥斯卡·范·赫尔登，范·赫尔登显然是荷兰名字，能看出他的祖先是荷兰人。机器允许他通过。",
        "Holder": "2",
        "Target": "奥斯卡·范·赫尔登的通行",
        "Aspect": "通行结果",
        "Opinion": "顺利通过",
        "Sentiment": "neutral",
        "Rationale": "奥斯卡·范·赫尔登顺利通过"
    },
    {
        "sentence": "当然，这是一个机器学习系统。它验证护照上的照片是否与它看到的照片一致。所以我在想，为什么这个设备歧视我，却允许皮特·韦尔和奥斯卡·范·赫尔登通行。",
        "Holder": "2",
        "Target": "机器学习系统",
        "Aspect": "识别偏见",
        "Opinion": "存在歧视",
        "Sentiment": "negative",
        "Rationale": "机器对不同人的识别结果不同"
    },
    {
        "sentence": "原因是使用的数据主要来自欧洲、北美和亚洲，而不是来自蒙加尼的家乡。为什么会这样？原因是因为资源的经济分布使得剑桥的资源远比我家乡的资源丰富。",
        "Holder": "2",
        "Target": "数据来源",
        "Aspect": "数据偏见",
        "Opinion": "数据不均衡",
        "Sentiment": "negative",
        "Rationale": "数据来源不均衡导致识别偏见"
    },
    {
        "sentence": "这就是发生的事情。我们使用这些设备，它们已经设计出来，输入了数据，而这些数据实际上反映了我们社会的经济模式。结果就是，像我和蒙加尼这样的人被拒绝进入，而皮特和奥斯卡被允许进入。",
        "Holder": "2",
        "Target": "设备设计",
        "Aspect": "设计偏见",
        "Opinion": "存在偏见",
        "Sentiment": "negative",
        "Rationale": "设备设计反映社会偏见"
    },
    {
        "sentence": "我来自南非，所以我知道这意味着什么。这意味着机器的行为开始模仿人的行为。实际上，虽然这些设备比人类更加理性、更加一致，它们做出的决策是一致的，但它们其实是有偏见的。",
        "Holder": "2",
        "Target": "机器行为",
        "Aspect": "行为模仿",
        "Opinion": "存在偏见",
        "Sentiment": "negative",
        "Rationale": "机器模仿人类行为导致偏见"
    },
    {
        "sentence": "那么，如何设计这些机器，让它们反映我们所希望的未来，而不是现在的未来，那个充满不对称性和矛盾的现实呢？这就是我对人工智能的看法。",
        "Holder": "2",
        "Target": "人工智能设计",
        "Aspect": "设计目标",
        "Opinion": "希望改进",
        "Sentiment": "neutral",
        "Rationale": "希望人工智能能反映更好的未来"
    },
    {
        "sentence": "我想起了英国著名作家查尔斯·狄更斯。在《双城记》中，讲的是“希望与绝望的较量”。我认为，人工智能将给我们带来很多希望，能够解决许多医学领域的重要问题。但它也会带来一些痛苦。",
        "Holder": "2",
        "Target": "人工智能影响",
        "Aspect": "影响两面性",
        "Opinion": "希望与痛苦并存",
        "Sentiment": "ambiguous",
        "Rationale": "人工智能既有希望也有痛苦"
    },
    {
        "sentence": "当我去到那个特定的国家时，突然让我感到很痛苦，我不会透露是哪儿。我曾经在玫瑰屋提到过，但那是个错误。",
        "Holder": "2",
        "Target": "个人经历",
        "Aspect": "情感体验",
        "Opinion": "感到痛苦",
        "Sentiment": "negative",
        "Rationale": "特定国家的经历让自己感到痛苦"
    },
    {
        "sentence": "多年来，我一直在努力帮助计算机像人类一样看待世界，而不像机器那样。在此过程中，我们要让计算机更像人类，少像机器，解决遇到的一些问题。",
        "Holder": "3",
        "Target": "计算机发展",
        "Aspect": "发展方向",
        "Opinion": "更像人类",
        "Sentiment": "positive",
        "Rationale": "希望计算机更人性化"
    },
    {
        "sentence": "我最初进入人工智能领域时，我负责一个非常大的众包资源项目，实际上这是MIT第一个应用众包的项目，叫做ConceptNet。",
        "Holder": "3",
        "Target": "个人经历",
        "Aspect": "项目介绍",
        "Opinion": "介绍项目",
        "Sentiment": "neutral",
        "Rationale": "介绍自己的项目经历"
    },
    {
        "sentence": "ConceptNet可以用于很多不同的领域，它主要通过众包和读取网络来创建。多年前，当这种技术还很新的时候，我们就开始用它来分析大学附近的餐馆评论。",
        "Holder": "3",
        "Target": "ConceptNet",
        "Aspect": "应用领域",
        "Opinion": "多领域应用",
        "Sentiment": "neutral",
        "Rationale": "介绍ConceptNet的应用领域"
    },
    {
        "sentence": "你知道，如果有什么能吸引人们关注，那就是人工智能能不能找到我们应该去哪里吃午餐？但我们很快注意到一个非常有趣的现象，那就是，AI根据它对世界的理解，更倾向于推荐某些类型的民族餐馆，而不是其他类型的餐馆。",
        "Holder": "3",
        "Target": "AI推荐",
        "Aspect": "推荐偏见",
        "Opinion": "存在偏见",
        "Sentiment": "neutral",
        "Rationale": "发现AI推荐存在偏见"
    },
    {
        "sentence": "于是，我们开始研究如何识别和去除自然语言处理中的偏见，并尽可能从我们每天使用和编程的系统中去除这种偏见。",
        "Holder": "3",
        "Target": "偏见研究",
        "Aspect": "研究方向",
        "Opinion": "去除偏见",
        "Sentiment": "positive",
        "Rationale": "致力于去除偏见"
    },
    {
        "sentence": "我还从事计算创造力的工作。所以我的目标是帮助计算机能够像人类一样思考、行动，并理解上下文。我的领域有很多进展。深度学习等技术已经改变了我们看待世界的方式，也改变了人工智能的工作方式。",
        "Holder": "3",
        "Target": "计算创造力",
        "Aspect": "研究目标",
        "Opinion": "提升计算机能力",
        "Sentiment": "positive",
        "Rationale": "希望提升计算机能力"
    },
    {
        "sentence": "但如果我们谈论现在的目标和深度学习的局限性，我们仍然需要新的东西，新的方法，才能突破这些障碍。我希望我们能通过今天的提问讨论一下这些问题。",
        "Holder": "3",
        "Target": "深度学习",
        "Aspect": "局限性",
        "Opinion": "需要新方法",
        "Sentiment": "neutral",
        "Rationale": "认识到深度学习的局限性"
    },
    {
        "sentence": "我们需要这样做，因为为了让人工智能能够实现目标，比如能够解释自己的行为，做出更加无偏的决策，我们将需要比现在创造的更深层次的人工智能。",
        "Holder": "3",
        "Target": "人工智能发展",
        "Aspect": "发展需求",
        "Opinion": "需要更深层次",
        "Sentiment": "positive",
        "Rationale": "希望人工智能能实现更高目标"
    },
    {
        "sentence": "偏见的问题已经提到过两次，这确实是一个非常相关的话题，因为，当然，我们正处于人工智能时代的起点，某种程度上，我们处于类似亚里士多德的时刻，正在从一个黑暗时期走出来。",
        "Holder": "4",
        "Target": "偏见问题",
        "Aspect": "问题重要性",
        "Opinion": "非常重要",
        "Sentiment": "positive",
        "Rationale": "认识到偏见问题的重要性"
    },
    {
        "sentence": "当然，人工智能已经有60年历史，但1956年约翰·麦卡锡在达特茅斯的著名研讨会上首次提出的人工智能概念，和我们今天所说的人工智能完全不同。",
        "Holder": "4",
        "Target": "人工智能历史",
        "Aspect": "历史变迁",
        "Opinion": "概念变化",
        "Sentiment": "neutral",
        "Rationale": "介绍人工智能的历史变迁"
    },
    {
        "sentence": "在我们尝试创建规则之前，现在我们尝试使用数学。这样做效果远好于以往，我们实际上可以实现它，它不再像以前那样脆弱。",
        "Holder": "4",
        "Target": "人工智能方法",
        "Aspect": "方法改进",
        "Opinion": "效果更好",
        "Sentiment": "positive",
        "Rationale": "使用数学方法改进了人工智能"
    },
    {
        "sentence": "因此，识别这些偏见至关重要，因为如果我们在基础上做错了，接下来我们可以预测会造成多大的混乱。因为人工智能的失败是灾难性的，好的结果也是一样的。",
        "Holder": "4",
        "Target": "偏见识别",
        "Aspect": "重要性",
        "Opinion": "至关重要",
        "Sentiment": "negative",
        "Rationale": "偏见识别错误会导致严重后果"
    },
    {
        "sentence": "我是这个小组的乐观主义者，虽然我认为我们要认识到这些偏见很重要，但尽管今天看起来这些偏见是实际的障碍，但我们会克服它们。",
        "Holder": "4",
        "Target": "偏见问题",
        "Aspect": "解决前景",
        "Opinion": "乐观克服",
        "Sentiment": "positive",
        "Rationale": "对克服偏见问题持乐观态度"
    },
    {
        "sentence": "并非完全克服，我们仍然会面临问题，但我们在统计学中也一直存在偏见问题。这几乎是上课的第一天就学到的内容。",
        "Holder": "4",
        "Target": "偏见问题",
        "Aspect": "问题普遍性",
        "Opinion": "普遍存在",
        "Sentiment": "neutral",
        "Rationale": "认识到偏见问题的普遍性"
    },
    {
        "sentence": "我相信大多数人会朝这个方向努力解决这些问题。",
        "Holder": "4",
        "Target": "解决问题",
        "Aspect": "解决信心",
        "Opinion": "有信心",
        "Sentiment": "positive",
        "Rationale": "相信大多数人会努力解决问题"
    },
    {
        "sentence": "所以，我们应该更多关注人工智能带来的好处，而不是过多关注其中的缺点。虽然我们更容易在舒适区谈论缺点，实际上这种倾向几乎成为了我们的“痼疾”，因为如果我们只讨论这些巨大的好处，看起来我们似乎没有批判性地对待技术。",
        "Holder": "4",
        "Target": "人工智能评价",
        "Aspect": "评价倾向",
        "Opinion": "关注好处",
        "Sentiment": "positive",
        "Rationale": "认为应更多关注人工智能的好处"
    },
    {
        "sentence": "我认为不对，人工智能技术有很多值得称赞的地方，我们应该以一种平衡的方式来看待它，既要赞美它的特殊之处，同时也要注意到它的问题。",
        "Holder": "4",
        "Target": "人工智能技术",
        "Aspect": "评价方式",
        "Opinion": "平衡看待",
        "Sentiment": "positive",
        "Rationale": "认为应平衡看待人工智能的优缺点"
    },
    {
        "sentence": "我的问题是，今天大多数的人工智能都基于自1950年代以来几乎没有变化的参数。具体来说，就是深度学习神经网络，它们使用大量数据集来生成行为决策，正如我们刚才讨论的那样。但所有这些神经网络都是有监督的，即编程并设置为进行学习。那么，你们认为我们是否已经接近了这种类型的人工智能能够达到的饱和点？",
        "Holder": "1",
        "Target": "人工智能发展",
        "Aspect": "技术饱和点",
        "Opinion": "怀疑接近饱和",
        "Sentiment": "neutral",
        "Rationale": "深度学习神经网络的技术基础自1950年代以来变化不大，且都是有监督的学习"
    },
    {
        "sentence": "我认为，当我们思考这个问题时，有一个非常有趣的地方，那就是现在的深度学习。现场有很多人可能已经听到过这个流行词，可能也在想它到底是什么意思。所以我先简要解释一下。深度学习是模式匹配，当我们非常擅长理解世界时，我们人类会学习模式。如果你把这种学习模式的能力发挥到极致，你得到的就是深度学习。它是一个很好的工具，我们已经研究了很长时间。如果你看看深度学习背后的数学，以及许多不同算法背后的数学，我们已经朝着正确的方向前进了一段时间，离目标越来越近。但当我们思考真正的智能时，我们需要的远不止是模式匹配。我认为我们已经看到，大家过于关注深度学习带来的短期惊人进展，这些是比较容易得到的成果，我们没有花太多时间去思考如何实现下一个层次。我认为这是非常重要的。我的MIT导师是Marvin Minski，他在看这些问题时，曾思考过低挂果与高挂果。如果我们回过头来，思考如何把人工智能提升到一个新高度，如何避免未来的障碍，我们确实需要开始关注高挂果部分。而这一部分就包括理解局限性。深度学习需要大量的数据。如果我们回想一下过去一周在星际争霸上看到的精彩结果，一个人如果想要购买相应的计算设备来训练这个系统，成本超过200万美元。如果每次我们要解决一个问题时，都需要花这么多钱在计算上，那么这根本无法扩展。我们可以进行概括学习，能够把在一个情境中学到的东西应用到另一个情境中，我们需要能够跳跃到下一个层次。这并不是说我们走错了方向，但我认为我们需要专注于此，并理解如何将这一点带到更前沿。",
        "Holder": "3",
        "Target": "深度学习",
        "Aspect": "技术局限性和发展方向",
        "Opinion": "需要关注更高层次的发展",
        "Sentiment": "positive",
        "Rationale": "深度学习虽然取得短期进展，但需要关注更高层次的发展和理解其局限性"
    },
    {
        "sentence": "好吧，也许我可以插一句，我们没有太认真地考虑过的一个问题是，深度学习方法实际上是相关性技术。我们用相关性技术来做因果推理。当然，这其中有危险，因为相关性不等于因果性，因果性也不等于相关性。第二点，是我们遇到的一个问题，我们曾花了很多时间研究如何利用深度学习来预测某个人在保险公司面临HIV风险的概率。例如，我们意识到输入数据并不总是完整的，也不总是完美的。统计学家花了很多时间研究如何在信息不完全的情况下做决策。由于在北美，甚至可能在亚洲的某些地区，数据的丰富性激发了很多热情。我认为我们已经忘记了如何设计能够在信息不完整的情况下做出决策的机器。更糟糕的是，算法的缺陷实际上迫使我们在算法设计上出现了一种新的范式。我不知道我说得清不清楚。你知道，我们甚至开始忽略其他类型的人工智能，因为深度学习并不是人工智能的全部。我知道很多人不喜欢这个观点，但其次，模糊系统仍然是某种形式的混合体，它将两种系统结合起来，这实际上是非常重要的。最后，我想谈谈透明性的问题，因为这些系统很难解释。究竟发生了什么。如果我们要将这些系统用于做出医学上的关键决策，甚至有些人考虑将它们用于武器，那么谁对这些决定负责？如果这些系统在没有人类干预的情况下做出决策，谁应该为这些决策负责？",
        "Holder": "2",
        "Target": "深度学习方法",
        "Aspect": "技术缺陷和责任问题",
        "Opinion": "存在严重问题",
        "Sentiment": "negative",
        "Rationale": "深度学习方法存在相关性不等于因果性的问题，且在信息不完整情况下决策困难，算法缺陷导致新范式出现，透明性问题和责任不明确"
    },
    {
        "sentence": "所有这些，都是非常有趣的。很有趣，因为它们巧妙地引出了我的观点。我尊重你们所说的每一点，但我不同意其中的三点。让我分别谈谈每一点，顺便说一下，这也是我们为什么要进行这场讨论的原因，对吧？首先是相关性。输出是相关性而非因果推理，这实际上我认为并不是问题。这取决于它的应用场景。在某些情况下，我们需要因果推理，但因果推理实际上是很难获得的。事实上，你真正需要的是通过实验和试验来获得因果关系，即使这样做出来的因果推理也不完美。但当你考虑当前的情况时，我们如何在社会中应用传统的统计学方法，自19世纪中期以来，尽管在更早的时候就可以做到，但我们可以追溯到高尔顿、费舍尔和皮尔森。今天，我们都生活在一个相关性的世界里，我们已经把人类送上了月球并安全带回，都是基于相关性，而不是完全理解因果关系。我们服用阿司匹林时，并不完全理解它在血液中的作用，但我们知道它有效。你真正考虑到人工智能如何工作时，深度学习神经网络在有许多层次和数百万交叉连接的情况下，我们能够做的事，如果你想象它的魔力，就是我们可以通过许多病理学检查图像，从中分析并将其与患者的生存率进行比较，然后根据结果预测哪些患者患有重度癌症，哪些没有。听起来很棒，我们的确没有因果关系，这没错。但关键是，机器学习算法能够比人工医生更好地发现癌症的迹象。在2012年的一项研究中，哈佛和斯坦福的Daphne Kohler和Andrew Beck就做了这个实验，机器学习算法能识别出11种最佳预测重度癌症的迹象，而医学从业者只知道其中的8种。有3种是算法识别出的，而人工医生和医学文献并不知道要去寻找这些迹象。因为它能发现人类看不见的模式，因为它通过机器学习，也就是通过机器视觉进行分析。所以，在这种情况下，你并不需要因果推理，你完全可以依靠相关性，做得更好。同样，在数据不完美或不完整的情况下，大数法则和大数据的世界实际上表明，数据的完整性并不是最重要的。事实上，如果有什么话要说，我们可以根据现有数据推断出不完整或缺失的数据。这几乎是这项技术中的公理。至于透明性，尽管我完全同意你说的，这是一个重要问题，我认为随着时间的推移，关于谁负责，谁应当为决策负责的问题会得到解答。最终，责任还是会落到人类身上。我同意你的一点，那就是今天系统的缺陷正在推动算法设计的新范式。我认为这是一个好事。",
        "Holder": "4",
        "Target": "深度学习相关性和透明性",
        "Aspect": "应用有效性和责任归属",
        "Opinion": "相关性足够有效，责任问题会解决",
        "Sentiment": "positive",
        "Rationale": "深度学习在发现癌症迹象等应用中表现出色，且大数据法则表明数据完整性不是最重要的问题，透明性和责任问题随时间会解决"
    },
    {
        "sentence": "那么，接下来我想合并两个问题，在向大家开放提问之前问一下。就像我们刚才讨论的那样，解决艰难问题，创造能够自我思考并做出决策的人工智能，一直是人工智能研究的目标。你们认为我们离创造具有意识的人工智能更近了吗？如果真的能够实现，那样的世界会让你感到害怕吗？",
        "Holder": "1",
        "Target": "具有意识的人工智能",
        "Aspect": "实现可能性和情感反应",
        "Opinion": "探讨实现可能性和恐惧感",
        "Sentiment": "neutral",
        "Rationale": "提出关于具有意识的人工智能的实现可能性和对此的情感反应的问题"
    },
    {
        "sentence": "那么，接下来我想合并两个问题，在向大家开放提问之前问一下。就像我们刚才讨论的那样，解决艰难问题，创造能够自我思考并做出决策的人工智能，一直是人工智能研究的目标。你们认为我们离创造具有意识的人工智能更近了吗？如果真的能够实现，那样的世界会让你感到害怕吗？",
        "Holder": "1",
        "Target": "人工智能研究",
        "Aspect": "创造具有意识的人工智能",
        "Opinion": "探讨进展和影响",
        "Sentiment": "neutral",
        "Rationale": "1在提出问题并探讨人工智能研究的进展和潜在影响"
    },
    {
        "sentence": "也许我可以先回答这个问题。其实很多已经设计的算法都是为了完成特定的任务。我至今还没有见过一种人工智能算法，它既能准确预测天气，又能为我泡咖啡，同时还会提醒我打电话给妈妈。之所以这样，是因为我们训练这些模型去完成特定的任务。现在，至关重要的一点是，意识并不是在一个有限的预测系统中自然产生的。因为实际上，区分我们和机器的根本特征就在于我们有意识。也许我不该多说意识的问题，因为我们其实并不知道意识究竟是什么，但我并不认为我们已经接近意识。正因如此，我认为机器会与我们共谋的这种观点，有点过于夸张。除非机器具备意识，你可以放心睡觉，不必担心机器。目前，我并不认为我们离看到具有意识的机器更近了。",
        "Holder": "2",
        "Target": "人工智能算法",
        "Aspect": "多功能性和意识",
        "Opinion": "认为目前离具有意识的机器还很远",
        "Sentiment": "negative",
        "Rationale": "2认为目前的算法只能完成特定任务且意识不是自然产生的"
    },
    {
        "sentence": "我完全同意，现有的人工智能就像美国分析公司Forrester所说的“务实AI”，它非常擅长解决特定任务。我认为，目前确实有很多工作在推进，使得人工智能可以胜任某些任务或任务群。但现在我们讨论的人工智能，能够总结文档，然后还能判断文档是正面还是负面的。这并不是能给你做咖啡的AI，也不是能预测天气的AI。所以在这方面，是的，我们更进一步了。但我想我还是有点乐观。我认为我们现在正在构建的工具真的很了不起，我们将能够利用它们一步步地接近强人工智能。但在这之间，仍然有很多事情需要做。所以我也不觉得需要担心，我认为我们还有很多工作要做。",
        "Holder": "3",
        "Target": "现有的人工智能",
        "Aspect": "任务能力和未来发展",
        "Opinion": "认为有进步但仍需努力",
        "Sentiment": "positive",
        "Rationale": "3认为现有AI在特定任务上有进步且对未来发展持乐观态度"
    },
    {
        "sentence": "我不想让讨论变得乏味，所以我同意大家的看法。人工智能的确能预测天气，人工智能的确能提醒我们给妈妈打电话。不过，我同意你对意识的看法。这根本不是问题。",
        "Holder": "4",
        "Target": "人工智能的功能",
        "Aspect": "多功能性和意识问题",
        "Opinion": "同意大家的看法",
        "Sentiment": "neutral",
        "Rationale": "4不想让讨论变得乏味且同意大家的看法"
    },
    {
        "sentence": "但通常情况下它并不是一个系统。你必须设计一个能帮助你的系统，另外一个系统可能会帮你泡咖啡。但是人类可以同时做所有这些事情。这也正是当它们的结构变得非常复杂时，才会有人希望认为这些机器最终能够拥有意识。",
        "Holder": "2",
        "Target": "人工智能系统",
        "Aspect": "系统复杂性和意识",
        "Opinion": "认为复杂结构可能导致意识期待",
        "Sentiment": "neutral",
        "Rationale": "2在解释为什么复杂结构可能导致对机器具备意识的期待"
    },
    {
        "sentence": "我认为，如果我们讨论的不是机器能做什么，而是机器是否能够同时做很多事情，的确是可以通过将多种算法结合起来，实现一个既能泡咖啡又能提醒打电话的系统。但关键在于，它是否能自动生成目标，并且拥有自我意识。",
        "Holder": "4",
        "Target": "机器的能力",
        "Aspect": "多功能性和自我意识",
        "Opinion": "机器可以多任务但缺乏自我意识",
        "Sentiment": "neutral",
        "Rationale": "讨论的是机器的功能和潜在局限"
    },
    {
        "sentence": "我觉得现在是时候让观众提问了。如果你举手的话，我们会把麦克风递给你。好，我们先来一个问题。",
        "Holder": "1",
        "Target": "观众提问",
        "Aspect": "提问时机",
        "Opinion": "现在是提问的好时机",
        "Sentiment": "neutral",
        "Rationale": "认为到了合适的互动环节"
    },
    {
        "sentence": "谢谢。基本上有两个问题。首先，你没有真正讨论过大规模自动化可能带来的社会影响。这个过程会是怎样的呢？我们会变成一个只去画画、停止工作的物种吗？还是说，富人会把所有的钱都掌握在手里，而我们这些普通人不能工作呢？第二个问题，如果我们降低意识层级，谈谈理解的话题。你们可能熟悉中国房间的思想实验。这个思想实验的意思是：假设你在一个房间里，手里有一本中文词典，给你输入一些信息，输出一些信息，外面的人看到你似乎懂中文，但实际上你根本不知道那些符号的含义。你认为计算机有可能逃脱这种局限，真正理解，而不仅仅是意识吗？这就是我的两个问题，谢谢。",
        "Holder": "5",
        "Target": "大规模自动化和社会影响",
        "Aspect": "社会影响和计算机理解能力",
        "Opinion": "担心自动化带来的社会问题和计算机理解的局限",
        "Sentiment": "negative",
        "Rationale": "对自动化可能带来的负面社会影响和计算机理解能力的怀疑"
    },
    {
        "sentence": "好，我来回答这个问题。关于工作的问题，也就是人工智能对工作世界的影响，人工智能领域有一个概念叫做莫拉维克困境。它基本上说，从进化的角度来看，越古老的技能比年轻的技能更容易被自动化。例如，我们读写文字仅仅有六千年的历史，但我们爬树的技能可能是在我们成为人类之前就已经有了。因此，制造一个能够爬树的机器人要比制造一个能够读书的机器人困难得多。所以，我认为影响是，按照我的观点，蓝领工作实际上是最容易受到威胁的。白领工作虽然也会受到影响，但蓝领工作是最危险的。另一个问题是，当你因为自动化而让人失业时，从经济的角度来看，总需求会下降。而生产是由需求驱动的。那么，谁来购买这些将要生产的商品呢？我认为我们整个经济体系在这一点上确实面临威胁。至于中国房间的思想实验，哲学家塞尔也称它为“中文房间”，我认为它其实是一种过于简化的智力评估方式。其次，人类即使你看不到他们在做什么，也能够表现出智能。我认为这只是一个思想实验，它是一个很好的思想实验，但我认为即使它是一个图灵测试，它不应该是一个事件，而应该是一个过程——一个与机器长时间互动的过程。到最后，我认为你能分辨出它是一个人类，而不是机器。",
        "Holder": "2",
        "Target": "人工智能对工作的影响和中国房间实验",
        "Aspect": "工作威胁和智能评估",
        "Opinion": "蓝领工作更易受威胁，中国房间实验过于简化",
        "Sentiment": "negative",
        "Rationale": "认为自动化对蓝领工作威胁大且经济体系面临风险，同时对中文房间实验的简化表示不满"
    },
    {
        "sentence": "我想我是这里对未来工作和自动化持乐观看法的人之一。稍微提供一些数据，根据麦肯锡和德勤的研究，目前大约5%的工作可以完全自动化，而大约30%的工作可以部分自动化。所以我们以前经历过很多次这样的周期，每次有重大的新技术或工业革命，我们都会看到这种情况发生，随之而来的是新的工作岗位。如果你回顾过去20年可能会创造出的工作岗位，大部分是以前根本没有的工作。我认为我们需要回过头来思考，如果有两类工作岗位被完全淘汰，那么接下来会发生什么？我认为，新的工作会出现，但它们会需要不同的技能。我们需要帮助这些工人，帮助整个社会的人员转型。这也是我们常常谈论的工作再培训问题，我认为它非常重要。但另一方面，对于那些工作内容部分被自动化的群体，我们必须学会与机器一起工作。正如肯所说，医生通过人工智能发现癌症的研究，很多研究表明，人类和计算机一起工作，效果比单独工作更好。我认为这也可以解释为什么人们有时在群体中工作得比单独工作更好。所以，当你看到人工智能打败了某个人类的基准时，如果你拿一群人来做同样的事，他们也会超越这个人工智能的基准，这也是很有意思的。所以，我们必须学会与机器更好地合作，我认为这会带来巨大的可能性，只要我们做对了。",
        "Holder": "3",
        "Target": "未来工作和自动化",
        "Aspect": "工作转型和人与机器合作",
        "Opinion": "乐观看待自动化带来的新机会",
        "Sentiment": "positive",
        "Rationale": "有数据和历史经验支持自动化会带来新的工作机会和社会转型"
    },
    {
        "sentence": "是的，我同意。我在凯瑟琳的观点上再补充几点。首先，如果你考虑人工智能如何与经济互动，虽然表面上看它可能会破坏许多工作，无论是蓝领还是白领工作，我大致同意大家的看法，尤其是蓝领工作。但它也会带来极大的生产力提升，实际上会引发一场真正的生产力繁荣。",
        "Holder": "4",
        "Target": "人工智能与经济互动",
        "Aspect": "对工作的影响",
        "Opinion": "破坏工作但提升生产力",
        "Sentiment": "positive",
        "Rationale": "虽然人工智能可能会破坏一些工作，但它会带来极大的生产力提升"
    },
    {
        "sentence": "举个例子，病理检查的成本，今天可能大约1000美元，但如果降到20便士（即某种机器和算法的成本），我们并不是说病理检查的数量会保持不变，而是它会变得更加便宜。我们将可能在任何时候对生物化学数据、唾液样本甚至大便样本进行病理检查，可能会发现一些我们以前不知道的疾病进展信息，能够在疾病严重到需要进行外科手术之前就发现问题。",
        "Holder": "4",
        "Target": "病理检查成本",
        "Aspect": "成本降低的影响",
        "Opinion": "病理检查变得更便宜和普及",
        "Sentiment": "positive",
        "Rationale": "病理检查成本降低会使得检查更加普及，能够早期发现疾病"
    },
    {
        "sentence": "在未来50年里，人们会感到惊讶，今天我们常听到有人被诊断为“剩余生命四个月”，或者肿瘤已经长到高尔夫球那么大，而他在早期其实可能只是一个沙粒的大小。这种事情怎么会发生？这个社会系统在工作时就是这样运作的。但如果成本降得很低，我们会看到更多的病理检查。",
        "Holder": "4",
        "Target": "未来病理检查",
        "Aspect": "早期疾病发现",
        "Opinion": "更多的病理检查能早期发现疾病",
        "Sentiment": "positive",
        "Rationale": "成本降低会导致更多的病理检查，从而能够早期发现疾病"
    },
    {
        "sentence": "经济历史中有很多例子，当某种商品的价格降低，虽然看起来会毁掉很多工作岗位，但我们实际上会看到这种商品的使用量增加。举个简单的例子，200年前，人们通常只有一两套衣服，只有富人才有窗帘，但到了19世纪中期，由于机械织布机的出现，布料开始普及，几乎应用到每个家庭中，甚至作为墙纸来装饰中产阶级家庭。所以，我们会看到相似的变化，虽然算法会给社会带来压力，但正如凯瑟琳指出的，工作将会发生变化，而我们需要做的就是帮助人们学会与算法合作。",
        "Holder": "4",
        "Target": "商品价格降低的影响",
        "Aspect": "使用量增加和工作变化",
        "Opinion": "价格降低会增加使用量并改变工作",
        "Sentiment": "positive",
        "Rationale": "历史上商品价格降低导致使用量增加并改变了工作形态"
    },
    {
        "sentence": "如果我们把目标设定为创造能够做出完全客观、理性决策的机器。那么，如果我们给这些机器输入的数据集本身就带有固有的偏见，我们如何能够创造出能够做出完全客观和理性决策的人工智能呢？显然，这个问题基于我们假设社会经济构成本身就带有固有的偏见，我们在未来也无法克服这些偏见。",
        "Holder": "6",
        "Target": "人工智能的客观性",
        "Aspect": "数据集偏见的影響",
        "Opinion": "数据集偏见影响决策客观性",
        "Sentiment": "negative",
        "Rationale": "输入数据集带有偏见，导致无法创造出完全客观和理性的人工智能"
    },
    {
        "sentence": "我可以给出一个非常实际的答案。正如我在开场时提到的，我经营着可能是最大的开源知识图谱，专注于人工智能领域。我们已经进行了20年的众包工作。最初，我们开始意识到数据中存在偏见，我们首先提出了一些测试来衡量并理解这些偏见。这些测试中，有些是微软在这个领域做的非常好的工作。通过了解这些偏见后，我们能够进入模型并去除这些偏见。最终，我们得到了一个与最初模型非常相似的模型，去除了这些特定的偏见，结果实际上模型的表现更好。",
        "Holder": "3",
        "Target": "数据偏见问题",
        "Aspect": "去除偏见的可行性",
        "Opinion": "可以通过计算方法去除偏见",
        "Sentiment": "positive",
        "Rationale": "通过测试和理解偏见，能够去除模型中的偏见并提升模型表现"
    },
    {
        "sentence": "所以答案是：有计算方法可以用来检查数据中的偏见。我们可以查看训练数据集并在事后进行修改。实际上，这是非常实际的，某种程度上，我对数据中的偏见持乐观态度，因为我认为这只是一个机器学习问题。",
        "Holder": "3",
        "Target": "数据偏见处理",
        "Aspect": "计算方法的可行性",
        "Opinion": "对处理偏见持乐观态度",
        "Sentiment": "positive",
        "Rationale": "有计算方法可以检查和修改数据中的偏见"
    },
    {
        "sentence": "嗯，理性问题显然是一个非常复杂的难题。对于机器来说，训练它们时，问题不仅仅在于数据，优化过程也是一个问题。在数学中，我们说这个优化问题是非凸的，其中很多部分是非凸的，这意味着你得到的最优解其实是你能够获得的最好的解。",
        "Holder": "2",
        "Target": "机器训练的理性问题",
        "Aspect": "优化过程的复杂性",
        "Opinion": "优化问题复杂且非凸",
        "Sentiment": "neutral",
        "Rationale": "优化问题本身的复杂性和非凸性"
    },
    {
        "sentence": "而这些模型的含义是，正如英国统计学家博克斯曾经说过的：“所有模型都是错误的，只不过有些模型有用。”",
        "Holder": "2",
        "Target": "模型的准确性",
        "Aspect": "模型的实用性",
        "Opinion": "模型虽错误但有用",
        "Sentiment": "neutral",
        "Rationale": "所有模型都有其局限性，但仍具有实用性"
    },
    {
        "sentence": "所有模型都是错的，但有些是有用的。",
        "Holder": "4",
        "Target": "模型",
        "Aspect": "模型的准确性",
        "Opinion": "模型有错但也有用",
        "Sentiment": "neutral",
        "Rationale": "模型虽然存在错误，但在某些情况下仍然具有实用价值"
    },
    {
        "sentence": "是的，完全正确。所有模型都是近似的，如果我们同意优化过程并不完美，所有模型都是错的但有用，那么我们就无法得到一个完全理性的机器。我们得到的将是一个有局限理性的机器。当然，这正是赫伯特·西蒙所说的，理性是有限的。你使用的数据、变量是有限的，你不能使用所有需要的变量，只能选择那些最有影响力的变量，否则你的模型将过于复杂，面临维度灾难和模型复杂性的平衡问题。所以我们必须接受机器不完全理性的事实。但有一点是确定的，我们也做过一些相关工作，机器其实在理性方面比人类要稍微理性一些。行为经济学家发现，人类是根本不理性的，而人工智能机器在理性方面稍微好一点，但它绝对不可能做到完全理性。",
        "Holder": "2",
        "Target": "模型的理性",
        "Aspect": "模型的理性程度",
        "Opinion": "机器理性有限但优于人类",
        "Sentiment": "neutral",
        "Rationale": "模型受限于数据和变量的选择，无法达到完全理性，但相比人类仍有一定优势"
    },
    {
        "sentence": "我在行为心理学上完全同意这一点，人类本质上是不理性的，卡尼曼和特沃斯基已经证明了这一点，但我稍微不同意问题中的假设：并不是所有数据都是偏见的。所有数据在某种程度上都可以说是“主观的”，因为是人类决定了什么是相关的，什么需要被收集。但如果你看一下实际情况，问题并不一定在于数据的偏见，而是人类在做数据选择时可能带入了先入为主的观念，而不是像人类偏见那样。我给你们举两个简单的例子。第一个是喷气发动机监控。我们都能同意，如果我们能够在飞机飞行过程中识别喷气发动机是否有可能出现故障，进行预测性维护，那是件好事。我们可以监控它，并利用人工智能来提高预测的准确性，判断它是否能正常运行，或是是否存在可能出现的维护问题。很难想象这方面会有什么偏见，对吧？同样的，你也可以想象，例如在病理学检查中计数血细胞。一个人类选择了某种方式来看待数据，而不是另一种方式，但这并不会像人类在某些群体上可能产生的偏见那样有问题。",
        "Holder": "4",
        "Target": "数据的偏见",
        "Aspect": "数据的主观性和偏见",
        "Opinion": "数据主观但不一定偏见",
        "Sentiment": "neutral",
        "Rationale": "数据的主观性不必然导致偏见，实际应用中数据的处理方式可能更关键"
    },
    {
        "sentence": "我认为，偏见不仅仅存在于数据上，它也可能出现在特征工程上，或者我们选择的特征和优化目标上。即使我们认为自己完全不带偏见，有时我们做的优化其实可能是在一个已经存在偏见的系统上进行的。所以，我认为非常重要的是，我们要仔细分析我们所做的事情，看看它们产生的效果是否能帮助我们理解偏见所在。这就是为什么我们要回到根本，问自己，能不能从特征工程或数据问题的角度出发，计算出这些偏见的来源并加以消除。我认为这是非常重要的。你知道，我有两种身份。在一半的时间里，我在企业界，另一半的时间里，我在学术界。在学术界，我们一直在谈论这个问题，就像今天我们在这里一样。而在企业界，直到最近五六个月，我才听到有人问我这个问题，而且只是在金融服务行业和一些咨询公司里讨论过。我认为，当我们讨论这个问题时，我们可以讨论现在我们所做的工作和努力是否足够好，我们可以想出很多改进的方法，但我们也必须教育外界，让人们意识到，即使在日常使用的系统中，也存在这些问题。我觉得商界现在并没有考虑到这一点。",
        "Holder": "3",
        "Target": "偏见的来源",
        "Aspect": "偏见的存在和消除",
        "Opinion": "偏见多方面存在需重视",
        "Sentiment": "neutral",
        "Rationale": "偏见不仅存在于数据还可能存在于特征工程等方面，需要全面分析和消除"
    },
    {
        "sentence": "嗨，我想问一下，能否详细讲讲我们在介绍中提到的法律在这个问题中的作用？目前在隐私设置、数据收集和数据使用方面的敌对情绪，是否会妨碍人工智能的发展，进而影响它迈向下一阶段？如果会，如何克服这些问题？",
        "Holder": "7",
        "Target": "法律在AI发展中的作用",
        "Aspect": "法律对AI发展的影响",
        "Opinion": "法律影响AI发展需探讨",
        "Sentiment": "neutral",
        "Rationale": "法律在隐私和数据使用方面的规定可能对AI发展产生阻碍，需要探讨如何克服"
    },
    {
        "sentence": "我同意Kenneth刚才说的一切。我也非常担心。我认为，除了这些问题外，我们还可以看看我们每天生活中留下的“数据碎片”，我们究竟给出了多少信息。比如，我们每个人每天都带着手机，随时都在泄露自己的地理位置，实际上，只需要四五个我们每天活动的位置点，就能识别出我们是谁。在我们刚开始做有目的的游戏时，Dr. Vonanakarini Mellen也收集了一些人们的个人信息。后来我们发现，事实上只需要一些关键词，就能推算出人们的身份信息。我们正在迎来数据隐私的严峻挑战。尽管我们在不断监管，然而，人们总能从我们在数字世界留下的碎片中推测出其他信息，这变得非常可怕。",
        "Holder": "3",
        "Target": "数据隐私",
        "Aspect": "数据泄露的严重性",
        "Opinion": "数据隐私面临严峻挑战",
        "Sentiment": "negative",
        "Rationale": "人们日常生活中的数据碎片被收集并用于识别身份，导致隐私泄露的风险增加"
    },
    {
        "sentence": "我认为隐私实际上是一个非常重要的问题。但我担心的是，这些收集数据的公司，它们给你提供合同，你必须点同意，然后它们就开始收集数据。我认为这种收集数据的方式是不公平的，我们实际上需要思考如何管理这些问题。第二个问题是，当一个位于硅谷的公司开始在布隆迪等地收集数据时，国际法并没有统一，但这些公司实际上在多个国家运营。那些被收集数据的人根本无法决定他们的数据将如何处理。我认为这是一个需要解决的问题。这不是一个单一国家能解决的问题，我们需要找到一种方法，能够聚集起来一起应对这个问题。我还想提出另一个问题，就是Kenneth你提到的社会数据，某些对社会有益的数据。如果某个人拥有一份从人口中收集的数据，可能这些人并不知道他们提供了多少，而这些数据实际上对社会有益，那么公司是否应该允许将这些数据永久保存呢？或者说，我们是否应该允许在五年后，这些数据可以公开，而不必完全保护数据所有者的权益。你知道，如果这些数据涉及某种疾病，我们可以将它公开，这样其他人就可以利用这些数据创造出能够解决该问题的技术。这几乎类似于数据的国有化概念，而这种事情实际上已经发生了。如果你发明了某样东西，你就可以申请专利。我认为你可以利用这个专利，可能是17年或20年，之后其他人也应该有机会利用它。我认为我们应该开始考虑这个框架，特别是对于那些对社会有益的数据，它们不能被公司永久拥有。",
        "Holder": "2",
        "Target": "数据收集方式",
        "Aspect": "数据收集的公平性和管理",
        "Opinion": "数据收集方式不公平且需要国际协作管理",
        "Sentiment": "negative",
        "Rationale": "公司通过合同强制收集数据且国际法不统一，导致数据管理不公平且难以控制"
    },
    {
        "sentence": "让我快速补充一点。这里有一些好消息。现在正在进行一些研究，探讨如何在保护隐私的前提下处理数据。实际上，推动这一运动的领军人物之一就在今晚的观众中，他就是安德鲁·特拉斯克，目前正在牛津大学攻读博士学位。因此，确实有一种方法可以审查数据，处理这些数据用于人工智能，但不会直接接触到数据本身。如果正确使用，这是很好的。但对于那些不想经历这一过程的人来说，这并不能消除人们日益强烈的担忧，那就是我们将会到处布置传感器，这些传感器可以通过我们的生物化学特征识别我们是谁。因此，我们的面孔已经成为一种条形码，通过面部识别技术，未来会变得更加复杂，能够更精确地辨认我们。当然，技术也不会忘记，它甚至能够在我们身体部位的部分数据的基础上识别我们。显然，这不是最终的答案。最终的答案必须是法律。法律可能是部分答案，但我们还需要找到其他创造性的方式来保护隐私，这些方法我们可能尚未想到。但我们最好开始思考。",
        "Holder": "4",
        "Target": "数据隐私保护",
        "Aspect": "隐私保护的技术和法律手段",
        "Opinion": "现有技术在保护隐私方面有进展但仍需法律和其他方法",
        "Sentiment": "neutral",
        "Rationale": "现有研究在保护隐私方面取得进展，但技术手段仍无法完全消除隐私担忧"
    },
    {
        "sentence": "哦，当然。我有几点意见。我完全同意这些观点。我认为五年时间太长了，数据在这段时间内会变得过时。但我认为，要做到这一点，正如Ken所说，我们必须提出并采用这些匿名化数据的方法。即使我们这么做了，正如我之前所说，有些数据可能会出现潜在的、紧急的用途。你从很少的数据中可以获得大量的信息，而你无法预见，发布这些数据后，未来会从中推断出什么信息。我意思是，我们都知道Netflix挑战，大家都知道第一个Netflix挑战发生时的推荐系统，后来第二次他们不得不撤回挑战，因为有人通过观看记录就能够推断出个人身份。所以，当我们看待数据时，我们会看到一些潜在的紧急信息。",
        "Holder": "3",
        "Target": "数据匿名化",
        "Aspect": "数据匿名化的有效性和风险",
        "Opinion": "数据匿名化方法需采用但存在潜在风险",
        "Sentiment": "negative",
        "Rationale": "即使采用匿名化方法，数据仍可能被用于推断个人信息，导致隐私泄露风险"
    }
]